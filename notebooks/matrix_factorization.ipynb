{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF , NormalPredictor\n",
    "from surprise import Dataset,Reader\n",
    "from surprise.model_selection import cross_validate,train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Factorization - user - item interactions\n",
    "*   Loading the user_item_rating dataset that I have created in the last stage.\n",
    "*   Using Random predictor as a baseline algorithem for recommendation of items to user.\n",
    "*   Applying two algorithms of MF - SVD\n",
    "*   MF algorithms aim to estimate/optimize the matrix U and V that will get minimum loss of the know rating of the user-items\n",
    "*   Given U and V we can predict the unknown rating of all users and items.\n",
    "*   The results of the algorithem will be validated by using RMSE score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating = pd.read_csv('../data/user_item_rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MF algorithems and prform cross validation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0669  1.0737  1.0668  1.0691  0.0032  \n",
      "Fit time          3.33    3.37    3.34    3.35    0.02    \n",
      "Test time         0.24    0.24    0.18    0.22    0.03    \n",
      "NMF\n",
      "Evaluating RMSE of algorithm NMF on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.2950  1.2876  1.2960  1.2929  0.0038  \n",
      "Fit time          5.05    4.98    5.04    5.02    0.03    \n",
      "Test time         0.23    0.22    0.22    0.22    0.01    \n",
      "Random\n",
      "Evaluating RMSE of algorithm NormalPredictor on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.4122  1.4156  1.4102  1.4127  0.0022  \n",
      "Fit time          0.07    0.09    0.09    0.08    0.01    \n",
      "Test time         0.26    0.24    0.25    0.25    0.01    \n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(user_item_rating[['user_id', 'item_id', 'rating']], reader)\n",
    "svd_algo = SVD()\n",
    "nmf_algo = NMF()\n",
    "algos= [('SVD',svd_algo),('NMF',nmf_algo),('Random',NormalPredictor())]\n",
    "for algo in algos :\n",
    "    print(algo[0])\n",
    "    cross_validate(algo[1], data, measures=['RMSE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the cross-validation results\n",
    "*   SVD rmse is 1.06 which is better than KNN basic algos that I have used for CF.\n",
    "*   NMF dont peform well as SVD with 1.29 , less than both of knn baisc.\n",
    "*   Both are better than random\n",
    "\n",
    "Now, I will focus on tunning the parameters of SVD ,by changing lr and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searching for best parameters...\")\n",
    "param_grid = {'n_epochs': [20, 30], 'lr_all': [0.005, 0.010],\n",
    "              'n_factors': [50, 100]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1171726781509062"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25,shuffle=False)\n",
    "#Train the model on the entire dataset\n",
    "user_knn_algo.fit(trainset)\n",
    "item_knn_algo.fit(trainset)\n",
    "random_algo.fit(trainset)\n",
    "\n",
    "#Evaluate on the same dataset\n",
    "user_knn_predictions = user_knn_algo.test(testset)\n",
    "item_knn_predictions = item_knn_algo.test(testset)\n",
    "random_knn_predictions = random_algo.test(testset)\n",
    "\n",
    "# Calculate and print RMSE\n",
    "accuracy.rmse(user_knn_predictions)\n",
    "# Calculate and print RMSE\n",
    "accuracy.rmse(item_knn_predictions)\n",
    "# Calculate and print RMSE\n",
    "accuracy.rmse(random_knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rmse is rasing to 1.11 if we split the dataset without shuffling which shows that the dataset is time-dependent.\n",
    "I will save the results that have been calculated for training on the whole dataset , for using in the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(user_id,trainset,algo, n=10):\n",
    "    # Get a list of all items and all users in the dataset\n",
    "    items = trainset.all_items()\n",
    "    users = trainset.all_users()\n",
    "    # Convert raw ids to inner ids\n",
    "    raw_user_id = user_id  # replace with the user ID you are interested in\n",
    "    inner_user_id = trainset.to_inner_uid(raw_user_id)\n",
    "    # Find items that the user has not rated yet\n",
    "    test_items = [trainset.to_raw_iid(item) for item in items if not trainset.ur[inner_user_id].__contains__(item)]\n",
    "    # Predict ratings for all the items not rated by the user\n",
    "    predictions = [algo.predict(raw_user_id, item) for item in test_items]\n",
    "    # Get the top N recommendations\n",
    "    top_n_items = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
    "    return top_n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit SVD on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2833b32a470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First train an SVD algorithm on the movielens dataset.\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trainset and the fitted algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "with open('../outputs/CF/algo_svd.sav', 'wb') as file:\n",
    "    pickle.dump(algo, file)\n",
    "with open('../outputs/CF/trainset.sav', 'wb') as file:\n",
    "    pickle.dump(trainset, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs-amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
