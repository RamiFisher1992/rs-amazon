{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF , NormalPredictor\n",
    "from surprise import Dataset,Reader\n",
    "from surprise.model_selection import cross_validate,train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from evaluation_metrics import precision_recall_at_k\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Factorization - user - item interactions\n",
    "*   Loading the user_item_rating dataset that I have created in the last stage.\n",
    "*   Using Random predictor as a baseline algorithem for recommendation of items to user.\n",
    "*   Applying two algorithms of MF - SVD\n",
    "*   MF algorithms aim to estimate/optimize the matrix U and V that will get minimum loss of the know rating of the user-items\n",
    "*   Given U and V we can predict the unknown rating of all users and items.\n",
    "*   The results of the algorithem will be validated by using RMSE score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_rating = pd.read_csv('../data/user_item_rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MF algorithems and prform cross validation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0672  1.0677  1.0723  1.0690  0.0023  \n",
      "Fit time          3.34    3.51    3.60    3.48    0.11    \n",
      "Test time         0.24    0.26    0.19    0.23    0.03    \n",
      "NMF\n",
      "Evaluating RMSE of algorithm NMF on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.2997  1.2935  1.2954  1.2962  0.0026  \n",
      "Fit time          5.05    5.05    5.14    5.08    0.04    \n",
      "Test time         0.22    0.22    0.22    0.22    0.00    \n",
      "Random\n",
      "Evaluating RMSE of algorithm NormalPredictor on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.4115  1.4226  1.4143  1.4161  0.0047  \n",
      "Fit time          0.07    0.09    0.09    0.08    0.01    \n",
      "Test time         0.25    0.25    0.25    0.25    0.00    \n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(user_item_rating[['user_id', 'item_id', 'rating']], reader)\n",
    "svd_algo = SVD()\n",
    "nmf_algo = NMF()\n",
    "algos= [('SVD',svd_algo),('NMF',nmf_algo),('Random',NormalPredictor())]\n",
    "for algo in algos :\n",
    "    print(algo[0])\n",
    "    cross_validate(algo[1], data, measures=['RMSE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the cross-validation results\n",
    "*   SVD rmse is 1.06 which is better than KNN basic algos that I have used for CF.\n",
    "*   NMF dont peform well as SVD with 1.29 , less than both of knn baisc.\n",
    "*   Both are better than random\n",
    "\n",
    "Now, I will focus on tunning the parameters of SVD ,by changing lr and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best parameters...\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for best parameters...\")\n",
    "param_grid = {'n_epochs': [20, 30,50], 'lr_all': [0.001,0.005, 0.010]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['RMSE'], cv=3)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score attained:  1.0660841145073692\n",
      "{'n_epochs': 30, 'lr_all': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized SVD model\n",
    "* Given the best parameters I have found , train a model and test the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0606126112715855"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = gs.best_params['rmse']\n",
    "svd_tunned_algo = SVD(n_epochs = params['n_epochs'], lr_all = params['lr_all'])\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd_tunned_algo.fit(trainset)\n",
    "svd_tunned_predictions = svd_tunned_algo.test(testset)\n",
    "# Calculate and print RMSE\n",
    "accuracy.rmse(svd_tunned_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use prcision@K and recall@K , samilar to knn algos.\n",
    "*   The results are not as high as KNN-user based , but are better the random recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preision@K for algo SVD is  0.7885869871903406\n",
      "Recall@K for algo SVD is  0.7885869871903406\n"
     ]
    }
   ],
   "source": [
    "predictions = svd_tunned_algo.test(testset)\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "precision_at_k = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "recall_at_k = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "# Precision and recall can then be averaged over all users\n",
    "print(f'Preision@K for algo SVD is  {precision_at_k}')\n",
    "print(f'Recall@K for algo SVD is  {precision_at_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit SVD on the all dataset for application usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2b3e7375f98>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First train an SVD algorithm on the movielens dataset.\n",
    "full_trainset = data.build_full_trainset()\n",
    "svd_tunned_algo.fit(full_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting user-item ids for evaluating specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../outputs/IDs/ids_items_dict.json', 'r') as file:\n",
    "    ids_items_dict = json.load(file)\n",
    "with open('../outputs/IDs/usernames_ids_dict.json', 'r') as file:\n",
    "    usernames_ids_dict = json.load(file)\n",
    "with open('../outputs/IDs/ids_usernames_dict.json', 'r') as file:\n",
    "    ids_usernames_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better evaluation of SVD i will user top_n recommendation of specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(user_id,dataset,algo, n=10):\n",
    "    # Get a list of all items and all users in the dataset\n",
    "    items = dataset.all_items()\n",
    "    # Convert raw ids to inner ids\n",
    "    raw_user_id = user_id  # replace with the user ID you are interested in\n",
    "    inner_user_id = dataset.to_inner_uid(raw_user_id)\n",
    "    # Find items that the user has not rated yet\n",
    "    test_items = [dataset.to_raw_iid(item) for item in items if not dataset.ur[inner_user_id].__contains__(item)]\n",
    "    # Predict ratings for all the items not rated by the user\n",
    "    predictions = [algo.predict(raw_user_id, item) for item in test_items]\n",
    "    # Get the top N recommendations\n",
    "    top_n_items = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
    "    return top_n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example I have take use named : \"kristina\" with historical items of 'Pet Supplies'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>itemName</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>vote</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>kristina</td>\n",
       "      <td>Pet ID Tags 8 Lines Engraving Available Size S...</td>\n",
       "      <td>Providence Engraving</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>$2.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15735</td>\n",
       "      <td>6297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>kristina</td>\n",
       "      <td>Chuckit Max Glow Ball</td>\n",
       "      <td>Chuckit</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>$5.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15735</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54520</th>\n",
       "      <td>kristina</td>\n",
       "      <td>Blue Buffalo Wilderness High Protein Grain Fre...</td>\n",
       "      <td>Blue Buffalo</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>$33.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15735</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userName                                           itemName  \\\n",
       "6875   kristina  Pet ID Tags 8 Lines Engraving Available Size S...   \n",
       "7322   kristina                              Chuckit Max Glow Ball   \n",
       "54520  kristina  Blue Buffalo Wilderness High Protein Grain Fre...   \n",
       "\n",
       "                      brand      category   price  rating  vote  user_id  \\\n",
       "6875   Providence Engraving  Pet Supplies   $2.99     5.0     0    15735   \n",
       "7322                Chuckit  Pet Supplies   $5.95     5.0     0    15735   \n",
       "54520          Blue Buffalo  Pet Supplies  $33.99     5.0     0    15735   \n",
       "\n",
       "       item_id  \n",
       "6875      6297  \n",
       "7322      1785  \n",
       "54520     1139  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv',index_col=[0])\n",
    "userName='kristina'\n",
    "#Get the items of specific userName#\n",
    "df[df['userName']==userName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When getting top_10 recommended items for kristina , we can see that not all items are related to pets , the top ones are more office products.\n",
    "*  MF are are more exploratory , that's why not all items are excatly the same as the user's history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prismacolor 3598T Premier Colored Pencils Soft Core 48 Pack\n",
      "Ethical Products SPOT Sponge Soccer Balls Cat Toy\n",
      "PaperPro Executive Stapler 3 1 Stapler One Finger Effort Spring Powered Stapler 1110\n",
      "Chuckit Max Glow Ball\n",
      "Sherpa Travel Original Deluxe Airline Approved Pet Carrier\n",
      "AmazonBasics Stainless Steel Dog Bowl\n",
      "Anthony Arrowroot Powder 5lb Batch Tested\n",
      "Temptations Mixup Treats Cats 16 Ounces\n",
      "UM 153 Signo Broad Point Gel Pen White Pack 3\n",
      "AmazonBasics Single Door amp Double Door Folding Metal Dog Crate\n"
     ]
    }
   ],
   "source": [
    "user_id = usernames_ids_dict[userName]\n",
    "#Get top n recommendation for specific user_id\n",
    "top_n_predictions = get_top_n(user_id,full_trainset,svd_tunned_algo,10)\n",
    "#Get top items ids\n",
    "top_items_ids = [obj.iid for obj in top_n_predictions]\n",
    "#Get top items rating\n",
    "top_k_ratings = [obj.est for obj in top_n_predictions]\n",
    "#Get items names according to item_ids\n",
    "top_k_items_names = (ids_items_dict[str(it_id)] for it_id in top_items_ids)\n",
    "for item in top_k_items_names:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trainset and the fitted algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "with open('../outputs/MF/svd_tunned_algo.sav', 'wb') as file:\n",
    "    pickle.dump(svd_tunned_algo, file)\n",
    "with open('../outputs/MF/trainset.sav', 'wb') as file:\n",
    "    pickle.dump(full_trainset, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs-amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
