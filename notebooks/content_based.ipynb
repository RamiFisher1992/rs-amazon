{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances\n",
    "from evaluation_metrics import precision_recall_at_k\n",
    "from collections import namedtuple\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained Sentence Transformer model\n",
    "sent_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "df = pd.read_csv('../data/preprocessed.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content Based Model\n",
    "*   First, I will generate embedding vector for the combination on itemName,brand and category\n",
    "*   Embbedding will be calculated by using all-MiniLM-L6-v2 pretrained sentence transformer\n",
    "*   By using embbedded vectors I will create the profile vector for each user and item by aggregating the each one of them.\n",
    "*   Then , calculate cosine similarity matrix of U*I user and items matrices\n",
    "*   Note , after generating embbedding I could have done PCA for reducing redundancy , but I didnt have the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate itemName and description\n",
    "def concatenate_textual_features(row):\n",
    "    return str(\"itemName : \" + row['itemName']) + \" brand : \" + str(row['brand'])+ \" category : \" + str(row['category'])\n",
    "\n",
    "# Function to encode a batch of texts\n",
    "def batch_encode(texts, batch_size=32):\n",
    "    return sent_model.encode(texts, batch_size=batch_size, show_progress_bar=True)\n",
    "\n",
    "#Calculate the user profile\n",
    "def user_profile_calculate(user_input_rating,user_item_matrix):\n",
    "    #calculate user_weight_items\n",
    "    user_weighted_items = user_input_rating.values.reshape(-1,1)*user_item_matrix\n",
    "    # Sum each column (axis 0 refers to rows)\n",
    "    sum_user_embedd = np.sum(user_weighted_items, axis=0).T\n",
    "\n",
    "    # Normalize the resulting vector\n",
    "    norm = np.linalg.norm(sum_user_embedd)\n",
    "    if norm == 0: \n",
    "        # Handle the case where the norm is 0\n",
    "        user_profile = sum_user_embedd\n",
    "    else:\n",
    "        user_profile = sum_user_embedd / norm\n",
    "    return pd.DataFrame(user_profile.values.reshape(1,-1))\n",
    "\n",
    "#Calculate the item profile\n",
    "def item_profile_calculate(item_avg_rating,item_vector):\n",
    "    item_vector = item_vector*item_avg_rating\n",
    "    norm = np.linalg.norm(item_vector)\n",
    "    if norm == 0: \n",
    "        # Handle the case where the norm is 0\n",
    "        item_profile = item_vector\n",
    "    else:\n",
    "        item_profile = item_vector / norm\n",
    "    return pd.DataFrame(item_profile.values.reshape(1,-1))\n",
    "\n",
    "#Clculate the user profile for each user#\n",
    "def generate_users_profiles(embeddings_df):\n",
    "    unique_users = embeddings_df['user_id'].unique()\n",
    "    users_profiles = pd.DataFrame()\n",
    "    for user_id in unique_users:\n",
    "        user_input_rating = embeddings_df[(embeddings_df.user_id==user_id)]['rating']\n",
    "        user_item_matrix = embeddings_df[(embeddings_df.user_id==user_id)].drop(columns=['user_id','item_id','rating'])\n",
    "        user_p = user_profile_calculate(user_input_rating,user_item_matrix)\n",
    "        users_profiles = pd.concat([users_profiles, user_p], ignore_index=True)\n",
    "    users_profiles['user_id'] = unique_users\n",
    "    return users_profiles\n",
    "\n",
    "#Clculate the item profile for each user#\n",
    "def generate_items_profiles(embeddings_df):\n",
    "    unique_items = embeddings_df['item_id'].unique()\n",
    "    item_profiles = pd.DataFrame()\n",
    "    for item_id in unique_items:\n",
    "        item_avg_rating = embeddings_df[embeddings_df.item_id==item_id]['rating'].mean()\n",
    "        item_vector = embeddings_df[embeddings_df.item_id==item_id].drop(columns=['user_id','item_id','rating']).iloc[0]\n",
    "        item_profile = item_profile_calculate(item_avg_rating,item_vector)\n",
    "        item_profiles = pd.concat([item_profiles, item_profile], ignore_index=True)\n",
    "    item_profiles['item_id'] = unique_items\n",
    "    return item_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the process that i have described above is done in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Generateing embedding for all items (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1512/1512 [13:43<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the features\n",
    "df['itemData'] = df.apply(concatenate_textual_features, axis=1)\n",
    "# Split the dataframe into batches and process each batch\n",
    "batch_size = 100  \n",
    "embeddings = batch_encode(df['itemData'].tolist(), batch_size=batch_size)\n",
    "embeddings_df = pd.concat([df[['user_id','item_id','rating']], pd.DataFrame(embeddings.tolist())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate users and items profiles\n",
    "users_profiles = generate_users_profiles(embeddings_df)\n",
    "items_profiles = generate_items_profiles(embeddings_df)\n",
    "\n",
    "# Extract the features (excluding the user_id and item_id)\n",
    "user_features = users_profiles.iloc[:, :-1].values\n",
    "item_features = items_profiles.iloc[:, :-1].values\n",
    "\n",
    "# Calculate cosine similarity between user vectors and item vectors\n",
    "similarity_matrix = cosine_similarity(user_features, item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading user-items ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../outputs/IDs/ids_items_dict.json', 'r') as file:\n",
    "    ids_items_dict = json.load(file)\n",
    "with open('../outputs/IDs/usernames_ids_dict.json', 'r') as file:\n",
    "    usernames_ids_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will be used for recommending top_k items for specific user with a given similarity metric according to the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return user_profile for given user_id\n",
    "def get_user_profile_by_user_id(users_profiles,user_id):    \n",
    "    user_data = users_profiles[users_profiles['user_id'] == user_id]\n",
    "    \n",
    "    if user_data.empty:\n",
    "        return users_profiles.drop(columns=['user_id']).mean().to_frame().transpose()\n",
    "    else:\n",
    "        return user_data.drop(columns=['user_id'])\n",
    "\n",
    "\n",
    "#Return user_profile for given user_id\n",
    "def get_item_profile_by_item_id(items_profiles, item_id):\n",
    "    item_data = items_profiles[items_profiles['item_id'] == item_id]\n",
    "    \n",
    "    if item_data.empty:\n",
    "        return items_profiles.drop(columns=['item_id']).mean().to_frame().transpose()\n",
    "    else:\n",
    "        return item_data.drop(columns=['item_id'])\n",
    "\n",
    "#Return item_name for given item_id\n",
    "def get_items_names(ids_items_dict, items_list):\n",
    "    top_items_names = [ids_items_dict[str(it_id)] for it_id in items_list]\n",
    "    return pd.DataFrame(top_items_names,columns=['itemName'])\n",
    "\n",
    "# Top items to recommend for specific user\n",
    "def get_top_k_items_for_specific_user(top_k,user_profile,items_profiles,user_items_ids,dis_metric):\n",
    "    #Filter items that the user didnt purchased#\n",
    "    unseen_items = items_profiles[~items_profiles['item_id'].isin(user_items_ids)]\n",
    "    \n",
    "    if dis_metric=='Cosine':\n",
    "        items_scores = cosine_similarity(user_profile,unseen_items.iloc[:, :-1].values)\n",
    "        #Looking for the higer cosin simillarity#\n",
    "        top_items_scores = np.sort(items_scores)[0][::-1][:top_k]\n",
    "        ratings = [cosine_similarity_to_rating(score) for score in top_items_scores]\n",
    "        top_items_indices = np.argsort(items_scores)[0][::-1][:top_k]\n",
    "    elif dis_metric=='Euclidean':\n",
    "        items_scores = euclidean_distances(user_profile,unseen_items.iloc[:, :-1].values)\n",
    "        #Looking for the lower euclidean#\n",
    "        top_items_scores = np.sort(items_scores)[0][:top_k]\n",
    "        ratings = [euclidean_to_rating(score) for score in top_items_scores]\n",
    "        top_items_indices = np.argsort(items_scores)[0][:top_k]\n",
    "    \n",
    "    top_items_ids = unseen_items.iloc[top_items_indices]['item_id'].values\n",
    "    return top_items_ids,top_items_scores,ratings\n",
    "\n",
    "# Convert the cosine similarity score to rating\n",
    "def cosine_similarity_to_rating(cosine_similarity): \n",
    "    normalized_score = (cosine_similarity + 1) / 2\n",
    "    rating = 1 + (normalized_score * 4)\n",
    "    return rating\n",
    "\n",
    "# Convert euclidean score to rating\n",
    "def euclidean_to_rating(euclidean_dist):\n",
    "    normalized_score = 1/(euclidean_dist + 1) \n",
    "    rating = 1 + (normalized_score * 4)\n",
    "    return rating\n",
    "\n",
    "#Recommen k items for a given user#\n",
    "def model_recommend(user_name,user_items_ids,k,dis_metric):\n",
    "    user_id = usernames_ids_dict.get(user_name,0)\n",
    "    user_profile = get_user_profile_by_user_id(users_profiles,user_id)\n",
    "    top_k_items_ids,top_items_scores,ratings = get_top_k_items_for_specific_user(k,user_profile,items_profiles,user_items_ids,dis_metric)\n",
    "    recommendation_df = get_items_names(ids_items_dict,top_k_items_ids)\n",
    "    recommendation_df['Metric_Score'] = top_items_scores\n",
    "    recommendation_df['Est_Rating'] = ratings\n",
    "    return recommendation_df\n",
    "\n",
    "#Recommen k items for a given user#\n",
    "def model_recommend_items(user_name,user_items_ids,k,dis_metric,df):\n",
    "    user_id = usernames_ids_dict.get(user_name,0)\n",
    "    user_profile = get_user_profile_by_user_id(users_profiles,user_id)\n",
    "    top_k_items_ids,top_items_scores,ratings = get_top_k_items_for_specific_user(k,user_profile,items_profiles,user_items_ids,dis_metric)\n",
    "    recommendation_df = get_items_names(ids_items_dict,top_k_items_ids)\n",
    "    item_neighbors = (df[df['item_id']==rid].iloc[0,1:4] for rid in top_k_items_ids)\n",
    "    top_k_df = pd.DataFrame()\n",
    "    for item in item_neighbors:\n",
    "        top_k_df = top_k_df.append(item, ignore_index=True)\n",
    "    return top_k_df\n",
    "\n",
    "#Get rating given a user_id and item_id\n",
    "def get_user_movie_rating_est(users_profiles,items_profiles,user_id,item_id,dist_metric='Cosine'):\n",
    "    user_profile = get_user_profile_by_user_id(users_profiles,user_id)\n",
    "    item_profile = get_item_profile_by_item_id(items_profiles,item_id)\n",
    "    if(dist_metric=='Cosine'):\n",
    "        rating = cosine_similarity_to_rating(user_profile@item_profile.T).values[0][0]\n",
    "    else:\n",
    "        rating = euclidean_to_rating(euclidean_distances(user_profile,item_profile)[0][0])\n",
    "    return rating\n",
    "\n",
    "#Return rmse for given list of user and items with ratings and the embbedding profiles#\n",
    "def rmse_cb_model(user_item_rating,users_profiles,items_profiles,dist_metric='Cosine'):\n",
    "    # Assuming user_item_rating is a DataFrame\n",
    "    errors = user_item_rating.apply(lambda row: (row['rating'] - get_user_movie_rating_est(users_profiles, items_profiles, row['user_id'], row['item_id'], dist_metric))**2, axis=1)\n",
    "    rmse = np.sqrt(errors.mean())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the user that was test with SVD , I will check which items are recommended to 'kristina' according to CB cosie-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>itemName</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>vote</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128729</th>\n",
       "      <td>Kristie D</td>\n",
       "      <td>quot Guinea Habitat rdquo Guinea Pig Cage amp ...</td>\n",
       "      <td>MidWest Homes Pets</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>55.770000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7642</td>\n",
       "      <td>11046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138704</th>\n",
       "      <td>Kristie D</td>\n",
       "      <td>Kaytee Clean amp Cozy Colored Small Animal Bed...</td>\n",
       "      <td>Kaytee</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7642</td>\n",
       "      <td>5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138810</th>\n",
       "      <td>Kristie D</td>\n",
       "      <td>Oxbow Animal Health Hamster Gerbil Fortified Food</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>20.178349</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7642</td>\n",
       "      <td>6831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userName                                           itemName  \\\n",
       "128729  Kristie D  quot Guinea Habitat rdquo Guinea Pig Cage amp ...   \n",
       "138704  Kristie D  Kaytee Clean amp Cozy Colored Small Animal Bed...   \n",
       "138810  Kristie D  Oxbow Animal Health Hamster Gerbil Fortified Food   \n",
       "\n",
       "                     brand      category      price  rating  vote  user_id  \\\n",
       "128729  MidWest Homes Pets  Pet Supplies  55.770000     5.0     0     7642   \n",
       "138704              Kaytee  Pet Supplies   8.270000     5.0     0     7642   \n",
       "138810               Oxbow  Pet Supplies  20.178349     5.0     0     7642   \n",
       "\n",
       "        item_id  \n",
       "128729    11046  \n",
       "138704     5003  \n",
       "138810     6831  "
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv',index_col=[0])\n",
    "userName='Kristie D'\n",
    "user_id = usernames_ids_dict[userName] \n",
    "#Get the items of specific userName#\n",
    "df[df['userName']==userName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accoding to the recommendation below\n",
    "*   Most of the items are related to Pet supplie\n",
    "*   Embedding vector seemed to act well in terms of getting similar items to the general profile of the user.\n",
    "*   This method is more conservative , items that arent ralted to the user list will not be recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting top K items for user by using Conten-Based cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemName</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oxbow Animal Health Cavy Cuisine Adult Guinea ...</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oxbow Animal Health Orchard Grass Hay Pets</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oxbow Carnivore Care Pet Supplement</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxbow Simple Rewards Natural Oven Baked Treats...</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oxbow Natural Science JOINT Supplement small a...</td>\n",
       "      <td>Oxbow</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            itemName  brand      category\n",
       "0  Oxbow Animal Health Cavy Cuisine Adult Guinea ...  Oxbow  Pet Supplies\n",
       "1         Oxbow Animal Health Orchard Grass Hay Pets  Oxbow  Pet Supplies\n",
       "2                Oxbow Carnivore Care Pet Supplement  Oxbow  Pet Supplies\n",
       "3  Oxbow Simple Rewards Natural Oven Baked Treats...  Oxbow  Pet Supplies\n",
       "4  Oxbow Natural Science JOINT Supplement small a...  Oxbow  Pet Supplies"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Content Based#\n",
    "user_items_ids = df[df['user_id']==user_id]['item_id']\n",
    "model_recommend_items(userName,user_items_ids,5,'Cosine',df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving users and items profiles for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save user profiles    \n",
    "users_profiles.columns = users_profiles.columns.astype(str)\n",
    "users_profiles.to_feather('../outputs/CB/users_profiles.feather')\n",
    "#Save item profiles\n",
    "items_profiles.columns = items_profiles.columns.astype(str)\n",
    "items_profiles.to_feather('../outputs/CB/items_profiles.feather')\n",
    "#Save embbeddings\n",
    "embeddings_df.columns = embeddings_df.columns.astype(str)\n",
    "embeddings_df.to_feather('../outputs/CB/items_user_content_embbedding.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of content-based model\n",
    "*   Model RMSE is 1.14 which is better than both collaborative-filtering models (user-based and item based).\n",
    "*   SVD still perform better , however that can be imporved by updated embedding with more informative features.\n",
    "*   In terms of precision@K and recall@K the results are close CF(item-based) with 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_feather('../outputs/CB/items_user_content_embbedding.feather')\n",
    "#splite embbedd users and items to train and test\n",
    "train_emb_df, test_emb_df = train_test_split(embeddings_df, test_size=0.25, random_state=42)\n",
    "\n",
    "#Generate users and items profiles according to the train set\n",
    "users_profiles = generate_users_profiles(train_emb_df)\n",
    "items_profiles = generate_items_profiles(train_emb_df)\n",
    "#Crate user_item_rating according to test set\n",
    "user_item_rating_test =  test_emb_df.loc[:,['user_id','item_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cosine = rmse_cb_model(user_item_rating_test,users_profiles,items_profiles,'Cosine')\n",
    "rmse_euclidean = rmse_cb_model(user_item_rating_test,users_profiles,items_profiles,'Eucl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE evalution\n",
    "*   Euclidean gets 1.58 which is worse than random model\n",
    "*   Cosine get 1.14 which is around the rmse of CF models and it can be exceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Content-Based Model (Cosine) is : 1.13226469756025\n",
      "RMSE Content-Based Model (Euclidean) is : 1.5738855231744706\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE Content-Based Model (Cosine) is : {rmse_cosine}')\n",
    "print(f'RMSE Content-Based Model (Euclidean) is : {rmse_euclidean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_cosine=[]\n",
    "Prediction = namedtuple(\"Prediction\", [\"uid\", \"iid\", \"r_ui\", \"est\", \"details\"])\n",
    "predictions_cosine = [\n",
    "    Prediction(row.user_id, row.item_id, row.rating, get_user_movie_rating_est(users_profiles, items_profiles, row.user_id, row.item_id,'Cosine'), '')\n",
    "    for _, row in user_item_rating_test.iterrows()\n",
    "]\n",
    "\n",
    "predictions_euc=[]\n",
    "predictions_euc = [\n",
    "    Prediction(row.user_id, row.item_id, row.rating, get_user_movie_rating_est(users_profiles, items_profiles, row.user_id, row.item_id,'Eucl'), '')\n",
    "    for _, row in user_item_rating_test.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preision@K for Content-Based Cosine  is  0.8040670869293485\n",
      "Recall@K for Content-Based Cosine is  0.8292484762694153\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls =  precision_recall_at_k(predictions_cosine, k=10, threshold=4)\n",
    "precision_at_k = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "recall_at_k = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "# Precision and recall can then be averaged over all users\n",
    "print(f'Preision@K for Content-Based Cosine  is  {precision_at_k}')\n",
    "print(f'Recall@K for Content-Based Cosine is  {recall_at_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalization of the rating score with euclidean metric seems to be out of scale.\n",
    "* May be caused by the fact that eculidean metric is not limit in a range.\n",
    "* As we would have excpected cosine similarity metric is more sutiable for the current mission.\n",
    "* Cosine measures the direction while Euclidean measures the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preision@K for Content-Based Euclidean is  0.07288650839606253\n",
      "Recall@K for Content-Based Euclidean is  0.054635498524829726\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls =  precision_recall_at_k(predictions_euc, k=10, threshold=4)\n",
    "precision_at_k = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "recall_at_k = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "# Precision and recall can then be averaged over all users\n",
    "print(f'Preision@K for Content-Based Euclidean is  {precision_at_k}')\n",
    "print(f'Recall@K for Content-Based Euclidean is  {recall_at_k}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
